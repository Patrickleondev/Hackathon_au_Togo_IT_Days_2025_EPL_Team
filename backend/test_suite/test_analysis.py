"""
Script de test pour l'analyse de fichiers
RansomGuard AI - Hackathon Togo IT Days 2025
"""

import asyncio
import os
import tempfile
import logging
from ml_engine.hybrid_detector import HybridDetector
from ml_engine.model_loader import get_model_loader

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_file_analysis():
    """Tester l'analyse de fichiers"""
    try:
        logger.info("üß™ Test de l'analyse de fichiers...")
        
        # Initialiser le d√©tecteur hybride
        hybrid_detector = HybridDetector()
        
        # Initialiser les mod√®les
        init_result = await hybrid_detector.initialize()
        logger.info(f"Initialisation: {init_result}")
        
        # Cr√©er un fichier de test
        with tempfile.NamedTemporaryFile(delete=False, suffix='.txt') as test_file:
            test_file.write(b"This is a test file for analysis")
            test_path = test_file.name
        
        try:
            # Analyser le fichier
            logger.info(f"Analyse du fichier: {test_path}")
            result = await hybrid_detector.analyze_file_hybrid(
                test_path, 
                {"filename": "test.txt", "upload_source": "test"}
            )
            
            logger.info("‚úÖ Analyse r√©ussie!")
            logger.info(f"R√©sultat: {result}")
            
            # V√©rifier la structure du r√©sultat
            required_fields = ['is_threat', 'confidence', 'threat_type', 'severity']
            for field in required_fields:
                if field not in result:
                    logger.error(f"‚ùå Champ manquant: {field}")
                else:
                    logger.info(f"‚úÖ {field}: {result[field]}")
            
        finally:
            # Nettoyer le fichier de test
            if os.path.exists(test_path):
                os.unlink(test_path)
        
        logger.info("üéâ Test termin√© avec succ√®s!")
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du test: {e}")
        raise

async def test_model_loading():
    """Tester le chargement des mod√®les"""
    try:
        logger.info("üß™ Test du chargement des mod√®les...")
        
        model_loader = get_model_loader()
        load_result = model_loader.load_models()
        
        logger.info(f"R√©sultat du chargement: {load_result}")
        
        if load_result.get('success', False):
            logger.info("‚úÖ Mod√®les charg√©s avec succ√®s!")
            
            # V√©rifier les mod√®les disponibles
            model_data = load_result.get('model_data', {})
            if 'models' in model_data:
                models = model_data['models']
                logger.info(f"üìä Mod√®les disponibles: {list(models.keys())}")
                
                for name, model in models.items():
                    logger.info(f"  ‚Ä¢ {name}: {type(model).__name__}")
        else:
            logger.warning("‚ö†Ô∏è √âchec du chargement des mod√®les")
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du test de chargement: {e}")
        raise

async def main():
    """Fonction principale de test"""
    logger.info("üöÄ D√©marrage des tests...")
    
    # Test 1: Chargement des mod√®les
    await test_model_loading()
    
    # Test 2: Analyse de fichiers
    await test_file_analysis()
    
    logger.info("üéØ Tous les tests termin√©s!")

if __name__ == "__main__":
    asyncio.run(main())
